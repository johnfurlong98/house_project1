{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# Housing Price Prediction Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* To explore and clean the housing dataset, preparing it for analysis.\n",
        "* To visualize correlations between various house attributes and sale prices.\n",
        "* To build predictive models to forecast housing prices based on selected features.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Housing dataset sourced from [Kaggle](https://www.kaggle.com/codeinstitute/housing-prices-data).\n",
        "* Python libraries: numpy, pandas, matplotlib, seaborn, ydata-profiling, plotly, ppscore, streamlit, feature-engine, imbalanced-learn, scikit-learn, xgboost, yellowbrick, Jinja2,          MarkupSafe, protobuf, ipywidgets, altair.\n",
        "* Datasets:\n",
        "  - `house_prices_records.csv`: Contains historical housing data including various features and sale prices.\n",
        "  - `inherited_houses.csv`: Contains data for the inherited houses for which we want to predict sale prices.\n",
        "\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Write here which files, code or artefacts you generate by the end of the notebook \n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* In case you have any additional comments that don't fit in the previous bullets, please state them here. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Section 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load required libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Section 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading first five rows from datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the datasets\n",
        "inherited_houses_path = '/workspace/house_project1/data/inherited_houses.csv'\n",
        "house_prices_records_path = '/workspace/house_project1/data/house_prices_records.csv'\n",
        "\n",
        "inherited_houses_df = pd.read_csv(inherited_houses_path)\n",
        "house_prices_df = pd.read_csv(house_prices_records_path)\n",
        "\n",
        "# Display the first few rows of each dataset\n",
        "print(\"Inherited Houses Data:\")\n",
        "print(inherited_houses_df.head())\n",
        "\n",
        "print(\"\\nHouse Prices Records Data:\")\n",
        "print(house_prices_df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " Data Cleaning & Preperation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3: Advanced Data Cleaning and Preparation for Both Files\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the datasets\n",
        "inherited_houses_df = pd.read_csv('/workspace/house_project1/data/inherited_houses.csv')\n",
        "house_prices_df = pd.read_csv('/workspace/house_project1/data/house_prices_records.csv')\n",
        "\n",
        "# Function to clean inherited houses data\n",
        "def clean_inherited_houses(data):\n",
        "    # Check for missing values\n",
        "    print(\"Missing values in inherited houses:\\n\", data.isnull().sum())\n",
        "\n",
        "    # Visualize missing values\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.heatmap(data.isnull(), cbar=False, cmap='viridis')\n",
        "    plt.title('Missing Values in Inherited Houses Data')\n",
        "    plt.show()\n",
        "\n",
        "    # Fill missing values for numerical and categorical features\n",
        "    for column in data.select_dtypes(include=[np.number]).columns:\n",
        "        data[column].fillna(data[column].median(), inplace=True)\n",
        "\n",
        "    for column in data.select_dtypes(include=[object]).columns:\n",
        "        data[column].fillna(data[column].mode()[0], inplace=True)\n",
        "\n",
        "    # Check data types and convert if necessary\n",
        "    print(\"Data types in inherited houses:\\n\", data.dtypes)\n",
        "   \n",
        "    # Convert categorical variables to 'category' dtype\n",
        "    categorical_cols = data.select_dtypes(include=[object]).columns\n",
        "    data[categorical_cols] = data[categorical_cols].astype('category')\n",
        "\n",
        "    # Detect and remove outliers using IQR method\n",
        "    def detect_outliers_iqr(data):\n",
        "        outlier_indices = []\n",
        "        for col in data.select_dtypes(include=[np.number]).columns:\n",
        "            Q1 = data[col].quantile(0.25)\n",
        "            Q3 = data[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "            outliers = data[(data[col] < lower_bound) | (data[col] > upper_bound)]\n",
        "            outlier_indices.extend(outliers.index.tolist())\n",
        "        return set(outlier_indices)\n",
        "\n",
        "    outlier_indices = detect_outliers_iqr(data)\n",
        "\n",
        "    # Remove outliers\n",
        "    data = data.drop(index=outlier_indices)\n",
        "    print(f\"Number of outliers removed from inherited houses: {len(outlier_indices)}\")\n",
        "\n",
        "    # Feature engineering: Create HouseAge feature\n",
        "    if 'YearBuilt' in data.columns:  # Ensure YearBuilt exists\n",
        "        data['HouseAge'] = 2024 - data['YearBuilt']\n",
        "\n",
        "    # Prepare the feature set and target variable\n",
        "    X_inherited = data.drop(['SalePrice'], axis=1)  # Replace 'SalePrice' accordingly\n",
        "    y_inherited = data['SalePrice']\n",
        "\n",
        "    # Encode categorical variables\n",
        "    X_inherited = pd.get_dummies(X_inherited, drop_first=True)\n",
        "\n",
        "    print(\"Final feature set shape for inherited houses:\", X_inherited.shape)\n",
        "    print(\"First few rows of features for inherited houses:\\n\", X_inherited.head())\n",
        "\n",
        "    return X_inherited, y_inherited\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to clean inherited houses data\n",
        "def clean_inherited_houses(data):\n",
        "    # Check for missing values\n",
        "    print(\"Missing values in inherited houses:\\n\", data.isnull().sum())\n",
        "\n",
        "    # Visualize missing values\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.heatmap(data.isnull(), cbar=False, cmap='viridis')\n",
        "    plt.title('Missing Values in Inherited Houses Data')\n",
        "    plt.show()\n",
        "\n",
        "    # Fill missing values for numerical and categorical features\n",
        "    for column in data.select_dtypes(include=[np.number]).columns:\n",
        "        data[column].fillna(data[column].median(), inplace=True)\n",
        "\n",
        "    for column in data.select_dtypes(include=[object]).columns:\n",
        "        data[column].fillna(data[column].mode()[0], inplace=True)\n",
        "\n",
        "    # Convert categorical variables to 'category' dtype\n",
        "    categorical_cols = data.select_dtypes(include=[object]).columns\n",
        "    data[categorical_cols] = data[categorical_cols].astype('category')\n",
        "\n",
        "    # Detect and remove outliers using IQR method\n",
        "    def detect_outliers_iqr(data):\n",
        "        outlier_indices = []\n",
        "        for col in data.select_dtypes(include=[np.number]).columns:\n",
        "            Q1 = data[col].quantile(0.25)\n",
        "            Q3 = data[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "            outliers = data[(data[col] < lower_bound) | (data[col] > upper_bound)]\n",
        "            outlier_indices.extend(outliers.index.tolist())\n",
        "        return set(outlier_indices)\n",
        "\n",
        "    outlier_indices = detect_outliers_iqr(data)\n",
        "\n",
        "    # Remove outliers\n",
        "    data = data.drop(index=outlier_indices)\n",
        "    print(f\"Number of outliers removed from inherited houses: {len(outlier_indices)}\")\n",
        "\n",
        "    # Feature engineering: Create HouseAge feature\n",
        "    if 'YearBuilt' in data.columns:  # Ensure YearBuilt exists\n",
        "        data['HouseAge'] = 2024 - data['YearBuilt']\n",
        "\n",
        "    # Prepare the feature set\n",
        "    X_inherited = data\n",
        "\n",
        "    # Encode categorical variables\n",
        "    X_inherited = pd.get_dummies(X_inherited, drop_first=True)\n",
        "\n",
        "    print(\"Final feature set shape for inherited houses:\", X_inherited.shape)\n",
        "    print(\"First few rows of features for inherited houses:\\n\", X_inherited.head())\n",
        "\n",
        "    return X_inherited\n",
        "\n",
        "# Clean the inherited houses dataset\n",
        "X_inherited = clean_inherited_houses(inherited_houses_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to clean house prices data\n",
        "def clean_house_prices(data):\n",
        "    # Check for missing values\n",
        "    print(\"Missing values in house prices:\\n\", data.isnull().sum())\n",
        "\n",
        "    # Visualize missing values\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.heatmap(data.isnull(), cbar=False, cmap='viridis')\n",
        "    plt.title('Missing Values in House Prices Data')\n",
        "    plt.show()\n",
        "\n",
        "    # Fill missing values for numerical features with median\n",
        "    for column in data.select_dtypes(include=[np.number]).columns:\n",
        "        data[column].fillna(data[column].median(), inplace=True)\n",
        "\n",
        "    # Encode categorical variables\n",
        "    categorical_cols = data.select_dtypes(include=[object]).columns\n",
        "    data[categorical_cols] = data[categorical_cols].astype('category')\n",
        "    data = pd.get_dummies(data, drop_first=True)\n",
        "\n",
        "    print(\"Final feature set shape for house prices:\", data.shape)\n",
        "    print(\"First few rows of features for house prices:\\n\", data.head())\n",
        "\n",
        "    return data\n",
        "\n",
        "# Clean the house prices dataset\n",
        "house_prices_df_cleaned = clean_house_prices(house_prices_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the dataset\n",
        "inherited_houses_df = pd.read_csv('/workspace/house_project1/data/inherited_houses.csv')\n",
        "\n",
        "# Function to handle missing values\n",
        "def handle_missing_values(data, num_imputation='median', cat_imputation='mode'):\n",
        "    for column in data.select_dtypes(include=[np.number]).columns:\n",
        "        if num_imputation == 'mean':\n",
        "            data[column].fillna(data[column].mean(), inplace=True)\n",
        "        elif num_imputation == 'median':\n",
        "            data[column].fillna(data[column].median(), inplace=True)\n",
        "        elif num_imputation == 'constant':\n",
        "            data[column].fillna(0, inplace=True)  # Example constant\n",
        "   \n",
        "    for column in data.select_dtypes(include=[object]).columns:\n",
        "        if cat_imputation == 'mode':\n",
        "            data[column].fillna(data[column].mode()[0], inplace=True)\n",
        "        elif cat_imputation == 'constant':\n",
        "            data[column].fillna('Unknown', inplace=True)  # Example constant\n",
        "\n",
        "    return data\n",
        "\n",
        "# Function to remove outliers using multiple methods\n",
        "def remove_outliers(data, method='IQR'):\n",
        "    if method == 'IQR':\n",
        "        for col in data.select_dtypes(include=[np.number]).columns:\n",
        "            Q1 = data[col].quantile(0.25)\n",
        "            Q3 = data[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "            data = data[(data[col] >= lower_bound) & (data[col] <= upper_bound)]\n",
        "    elif method == 'Z-score':\n",
        "        from scipy import stats\n",
        "        z_scores = np.abs(stats.zscore(data.select_dtypes(include=[np.number])))\n",
        "        data = data[(z_scores < 3).all(axis=1)]\n",
        "    elif method == 'IsolationForest':\n",
        "        iso = IsolationForest(contamination=0.05)  # Adjust contamination as needed\n",
        "        preds = iso.fit_predict(data.select_dtypes(include=[np.number]))\n",
        "        data = data[preds != -1]\n",
        "   \n",
        "    return data\n",
        "\n",
        "# Function to normalize features\n",
        "def normalize_features(data, method='standard'):\n",
        "    numerical_cols = data.select_dtypes(include=[np.number]).columns\n",
        "    if method == 'standard':\n",
        "        scaler = StandardScaler()\n",
        "    elif method == 'minmax':\n",
        "        scaler = MinMaxScaler()\n",
        "    elif method == 'robust':\n",
        "        scaler = RobustScaler()\n",
        "   \n",
        "    data[numerical_cols] = scaler.fit_transform(data[numerical_cols])\n",
        "    return data\n",
        "\n",
        "# Function to clean inherited houses data\n",
        "def clean_inherited_houses(data, num_imputation='median', cat_imputation='mode', outlier_method='IQR', normalization_method='standard'):\n",
        "    print(\"Initial shape of the dataset:\", data.shape)\n",
        "\n",
        "    # Step 1: Handle missing values\n",
        "    data = handle_missing_values(data, num_imputation, cat_imputation)\n",
        "\n",
        "    # Step 2: Remove outliers\n",
        "    data = remove_outliers(data, method=outlier_method)\n",
        "\n",
        "    # Step 3: Feature Engineering\n",
        "    data['HouseAge'] = 2024 - data['YearBuilt']\n",
        "    data['TotalArea'] = (data['1stFlrSF'] + data['2ndFlrSF'] +\n",
        "                         data['TotalBsmtSF'] + data['GarageArea'] +\n",
        "                         data['WoodDeckSF'] + data['OpenPorchSF'] +\n",
        "                         data['EnclosedPorch'])\n",
        "\n",
        "    # Step 4: Encode categorical variables\n",
        "    categorical_cols = data.select_dtypes(include=[object]).columns\n",
        "    data[categorical_cols] = data[categorical_cols].astype('category')\n",
        "    data = pd.get_dummies(data, drop_first=True)\n",
        "\n",
        "    # Step 5: Normalize numerical features\n",
        "    data = normalize_features(data, method=normalization_method)\n",
        "\n",
        "    print(\"\\nFinal feature set shape for inherited houses:\", data.shape)\n",
        "    print(\"First few rows of features for inherited houses:\\n\", data.head())\n",
        "\n",
        "    return data\n",
        "\n",
        "# Clean the inherited houses dataset with different parameters\n",
        "inherited_houses_df_cleaned = clean_inherited_houses(\n",
        "    inherited_houses_df,\n",
        "    num_imputation='median',\n",
        "    cat_imputation='mode',\n",
        "    outlier_method='IQR',\n",
        "    normalization_method='standard'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset (ensure this path is correct)\n",
        "house_prices_df = pd.read_csv('/workspace/house_project1/data/house_prices_records.csv')\n",
        "\n",
        "# Function to visualize missing values\n",
        "def visualize_missing_values(data, title='Missing Values'):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.heatmap(data.isnull(), cbar=False, cmap='viridis')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Columns')\n",
        "    plt.ylabel('Rows')\n",
        "    plt.show()\n",
        "\n",
        "# Function to display summary statistics\n",
        "def display_summary_statistics(data, title='Summary Statistics'):\n",
        "    print(f\"\\n{title}:\")\n",
        "    display(data.describe(include='all'))\n",
        "\n",
        "# Function to display final dataset shape\n",
        "def display_final_shape(data):\n",
        "    print(f\"\\nFinal shape of the dataset: {data.shape}\")\n",
        "\n",
        "# Function to handle missing values\n",
        "def handle_missing_values(data, num_imputation='median', cat_imputation='mode'):\n",
        "    # Fill missing values for numerical features\n",
        "    for column in data.select_dtypes(include=[np.number]).columns:\n",
        "        data[column].fillna(data[column].median(), inplace=True)\n",
        "\n",
        "    # Fill missing values for categorical features\n",
        "    for column in data.select_dtypes(include=[object]).columns:\n",
        "        data[column].fillna(data[column].mode()[0], inplace=True)\n",
        "\n",
        "    return data\n",
        "\n",
        "# Function to remove outliers based on IQR\n",
        "def remove_outliers(data, method='IQR'):\n",
        "    if method == 'IQR':\n",
        "        for column in data.select_dtypes(include=[np.number]).columns:\n",
        "            Q1 = data[column].quantile(0.25)\n",
        "            Q3 = data[column].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - 1.5 * IQR\n",
        "            upper_bound = Q3 + 1.5 * IQR\n",
        "            data = data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n",
        "    return data\n",
        "\n",
        "# Function to normalize numerical features\n",
        "def normalize_features(data, method='standard'):\n",
        "    if method == 'standard':\n",
        "        from sklearn.preprocessing import StandardScaler\n",
        "        scaler = StandardScaler()\n",
        "        numerical_cols = data.select_dtypes(include=[np.number]).columns\n",
        "        data[numerical_cols] = scaler.fit_transform(data[numerical_cols])\n",
        "    return data\n",
        "\n",
        "# Function to clean house prices data with detailed output\n",
        "def clean_house_prices(data, num_imputation='median', cat_imputation='mode', outlier_method='IQR', normalization_method='standard'):\n",
        "    print(\"Initial shape of the dataset:\", data.shape)\n",
        "   \n",
        "    # Display initial summary statistics\n",
        "    display_summary_statistics(data, title='Initial Summary Statistics')\n",
        "\n",
        "    # Step 1: Handle missing values\n",
        "    visualize_missing_values(data, title='Missing Values Before Cleaning')\n",
        "    data = handle_missing_values(data, num_imputation, cat_imputation)\n",
        "\n",
        "    # Step 2: Remove outliers\n",
        "    data_before_outlier_removal = data.copy()\n",
        "    data = remove_outliers(data, method=outlier_method)\n",
        "\n",
        "    # Visualize outliers before and after\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.boxplot(data=data_before_outlier_removal.select_dtypes(include=[np.number]).melt(value_vars=data_before_outlier_removal.select_dtypes(include=[np.number]).columns), x='variable', y='value')\n",
        "    plt.title('Outliers Before Removal')\n",
        "    plt.xticks(rotation=90)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.boxplot(data=data.select_dtypes(include=[np.number]).melt(value_vars=data.select_dtypes(include=[np.number]).columns), x='variable', y='value')\n",
        "    plt.title('Outliers After Removal')\n",
        "    plt.xticks(rotation=90)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Step 3: Encode categorical variables\n",
        "    categorical_cols = data.select_dtypes(include=[object]).columns\n",
        "    data[categorical_cols] = data[categorical_cols].astype('category')\n",
        "    data = pd.get_dummies(data, drop_first=True)\n",
        "\n",
        "    # Step 4: Normalize numerical features\n",
        "    data = normalize_features(data, method=normalization_method)\n",
        "\n",
        "    # Display final summary statistics\n",
        "    display_summary_statistics(data, title='Final Summary Statistics')\n",
        "   \n",
        "    # Display final shape\n",
        "    display_final_shape(data)\n",
        "   \n",
        "    return data\n",
        "\n",
        "# Clean the house prices dataset and display results\n",
        "house_prices_df_cleaned = clean_house_prices(\n",
        "    house_prices_df,\n",
        "    num_imputation='median',\n",
        "    cat_imputation='mode',\n",
        "    outlier_method='IQR',\n",
        "    normalization_method='standard'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset \n",
        "house_prices_df = pd.read_csv('/workspace/house_project1/data/house_prices_records.csv')\n",
        "\n",
        "# Function to visualize missing values\n",
        "def visualize_missing_values(data, title='Missing Values'):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.heatmap(data.isnull(), cbar=False, cmap='viridis')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Columns')\n",
        "    plt.ylabel('Rows')\n",
        "    plt.show()\n",
        "\n",
        "# Function to display summary statistics\n",
        "def display_summary_statistics(data, title='Summary Statistics'):\n",
        "    print(f\"\\n{title}:\")\n",
        "    display(data.describe(include='all'))\n",
        "\n",
        "# Function to display final dataset shape\n",
        "def display_final_shape(data):\n",
        "    print(f\"\\nFinal shape of the dataset: {data.shape}\")\n",
        "\n",
        "# Function to handle missing values\n",
        "def handle_missing_values(data):\n",
        "    # Fill missing values for numerical features\n",
        "    for column in data.select_dtypes(include=[np.number]).columns:\n",
        "        data[column].fillna(data[column].median(), inplace=True)\n",
        "\n",
        "    # Fill missing values for categorical features\n",
        "    for column in data.select_dtypes(include=[object]).columns:\n",
        "        data[column].fillna(data[column].mode()[0], inplace=True)\n",
        "\n",
        "    return data\n",
        "\n",
        "# Function to remove outliers based on IQR\n",
        "def remove_outliers(data):\n",
        "    for column in data.select_dtypes(include=[np.number]).columns:\n",
        "        Q1 = data[column].quantile(0.25)\n",
        "        Q3 = data[column].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "        data = data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n",
        "    return data\n",
        "\n",
        "# Function to normalize numerical features\n",
        "def normalize_features(data):\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    scaler = StandardScaler()\n",
        "    numerical_cols = data.select_dtypes(include=[np.number]).columns\n",
        "    data[numerical_cols] = scaler.fit_transform(data[numerical_cols])\n",
        "    return data\n",
        "\n",
        "# Function to clean house prices data with detailed output\n",
        "def clean_house_prices(data):\n",
        "    print(\"Initial shape of the dataset:\", data.shape)\n",
        "   \n",
        "    # Display initial summary statistics\n",
        "    display_summary_statistics(data, title='Initial Summary Statistics')\n",
        "\n",
        "    # Step 1: Handle missing values\n",
        "    visualize_missing_values(data, title='Missing Values Before Cleaning')\n",
        "    data = handle_missing_values(data)\n",
        "\n",
        "    # Step 2: Remove outliers\n",
        "    data_before_outlier_removal = data.copy()\n",
        "    data = remove_outliers(data)\n",
        "\n",
        "    # Dynamic Boxplot Visualization for Outliers\n",
        "    numerical_features = data.select_dtypes(include=[np.number]).columns\n",
        "    n_features = len(numerical_features)\n",
        "   \n",
        "    # Adjusting layout based on the number of features\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(6 * n_features // 2, 6))  # Dynamic size\n",
        "    plt.subplots_adjust(wspace=0.3)\n",
        "\n",
        "    sns.boxplot(data=data_before_outlier_removal[numerical_features].melt(), x='variable', y='value', ax=axes[0])\n",
        "    axes[0].set_title('Outliers Before Removal')\n",
        "    axes[0].tick_params(axis='x', rotation=90)\n",
        "\n",
        "    sns.boxplot(data=data[numerical_features].melt(), x='variable', y='value', ax=axes[1])\n",
        "    axes[1].set_title('Outliers After Removal')\n",
        "    axes[1].tick_params(axis='x', rotation=90)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    # Step 3: Encode categorical variables\n",
        "    categorical_cols = data.select_dtypes(include=[object]).columns\n",
        "    data[categorical_cols] = data[categorical_cols].astype('category')\n",
        "    data = pd.get_dummies(data, drop_first=True)\n",
        "\n",
        "    # Step 4: Normalize numerical features\n",
        "    data = normalize_features(data)\n",
        "\n",
        "    # Display final summary statistics\n",
        "    display_summary_statistics(data, title='Final Summary Statistics')\n",
        "   \n",
        "    # Display final shape\n",
        "    display_final_shape(data)\n",
        "   \n",
        "    return data\n",
        "\n",
        "# Clean the house prices dataset and display results\n",
        "house_prices_df_cleaned = clean_house_prices(house_prices_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Load your dataset from the specified path\n",
        "file_path = \"/workspace/house_project1/data/house_prices_records.csv\"\n",
        "house_prices_df = pd.read_csv(file_path)\n",
        "\n",
        "# Define feature columns and target\n",
        "selected_features = [\n",
        "    '1stFlrSF', '2ndFlrSF', 'BedroomAbvGr', 'BsmtFinSF1', 'BsmtUnfSF',\n",
        "    'EnclosedPorch', 'GarageArea', 'GarageYrBlt', 'GrLivArea', 'KitchenQual',\n",
        "    'LotArea', 'LotFrontage', 'MasVnrArea', 'OpenPorchSF', 'OverallCond',\n",
        "    'OverallQual', 'TotalBsmtSF', 'WoodDeckSF', 'YearBuilt', 'YearRemodAdd'\n",
        "]\n",
        "X = house_prices_df[selected_features].copy()\n",
        "y = house_prices_df['SalePrice']\n",
        "\n",
        "# Separate numerical and categorical columns\n",
        "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "# Define the preprocessing pipelines\n",
        "# Numerical Pipeline\n",
        "num_pipeline = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Categorical Pipeline\n",
        "cat_pipeline = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(drop='first', sparse_output=False))\n",
        "])\n",
        "\n",
        "# Combine the pipelines using ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', num_pipeline, num_cols),\n",
        "        ('cat', cat_pipeline, cat_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Apply transformations to the training data\n",
        "X_processed = preprocessor.fit_transform(X)\n",
        "\n",
        "# Convert the processed array back to DataFrame for ease of interpretation\n",
        "# This step is useful for accessing column names after encoding\n",
        "cat_feature_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(cat_cols)\n",
        "all_feature_names = num_cols + list(cat_feature_names)\n",
        "X_processed_df = pd.DataFrame(X_processed, columns=all_feature_names)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_processed_df, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model Training\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions and Model Evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "# Display evaluation metrics\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
        "\n",
        "# Visualize feature importances\n",
        "feature_importances = model.feature_importances_\n",
        "importance_df = pd.DataFrame({'Feature': all_feature_names, 'Importance': feature_importances})\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
        "plt.title(\"Feature Importances from Random Forest Model\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(house_prices_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/workspace/house_project1/data/house_prices_records.csv')\n",
        "\n",
        "# Display the first few rows to verify it loaded correctly\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/workspace/house_project1/data/house_prices_records.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display initial information about the dataset\n",
        "print(\"Initial Data Overview:\")\n",
        "print(df.info())\n",
        "print(\"\\nInitial Data Summary:\")\n",
        "print(df.describe())\n",
        "\n",
        "# Data Preprocessing\n",
        "# Handle missing values by filling them with median (numerical) or mode (categorical)\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object':\n",
        "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
        "    else:\n",
        "        df[col].fillna(df[col].median(), inplace=True)\n",
        "\n",
        "# Display the updated dataset information\n",
        "print(\"\\nAfter Handling Missing Values:\")\n",
        "print(df.info())\n",
        "\n",
        "# Encode categorical variables using one-hot encoding\n",
        "df_encoded = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "# Filter for numeric columns in the encoded DataFrame\n",
        "numeric_df_encoded = df_encoded.select_dtypes(include=[np.number])\n",
        "\n",
        "# Correlation Heatmap of numerical features\n",
        "plt.figure(figsize=(16, 10))\n",
        "sns.heatmap(numeric_df_encoded.corr(), annot=False, cmap='coolwarm', linewidths=0.5)\n",
        "plt.title('Correlation Heatmap Including Encoded Categorical Features')\n",
        "plt.show()\n",
        "\n",
        "# Key insights from correlation\n",
        "# Display highly correlated features with 'SalePrice'\n",
        "correlation_matrix = numeric_df_encoded.corr()\n",
        "high_corr_features = correlation_matrix['SalePrice'].sort_values(ascending=False)\n",
        "print(\"\\nHighly Correlated Features with SalePrice:\")\n",
        "print(high_corr_features[high_corr_features > 0.5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exploratory Data Analysis: Visualizing the relationship between SalePrice and key features\n",
        "high_corr_features = ['OverallQual', 'GrLivArea', 'GarageArea', 'TotalBsmtSF', '1stFlrSF', 'YearBuilt', 'YearRemodAdd']\n",
        "\n",
        "# Set up the plotting area\n",
        "plt.figure(figsize=(15, 12))\n",
        "\n",
        "# Loop through each feature and create a scatter plot to see the relationship with SalePrice\n",
        "for i, feature in enumerate(high_corr_features, 1):\n",
        "    plt.subplot(3, 3, i)\n",
        "    sns.scatterplot(x=df[feature], y=df['SalePrice'])\n",
        "    plt.title(f'SalePrice vs {feature}')\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel('SalePrice')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Pairplot for in-depth analysis\n",
        "sns.pairplot(df, vars=high_corr_features + ['SalePrice'], diag_kind='kde')\n",
        "plt.suptitle('Pairplot of Highly Correlated Features with SalePrice', y=1.02)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Step 1: Select Features Based on Correlation\n",
        "# Using features with high correlation to SalePrice for the model\n",
        "selected_features = ['OverallQual', 'GrLivArea', 'GarageArea', \n",
        "                     'TotalBsmtSF', '1stFlrSF', 'YearBuilt', 'YearRemodAdd']\n",
        "\n",
        "X = df[selected_features]\n",
        "y = df['SalePrice']\n",
        "\n",
        "# Step 2: Split the Data into Training and Testing Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Data Preprocessing - Scaling\n",
        "# Standardize the features to ensure they all have a mean of 0 and standard deviation of 1\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Step 4: Train the Model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Make Predictions and Evaluate the Model\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = mse ** 0.5\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Print evaluation results\n",
        "print(\"Model Performance:\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
        "print(f\"R^2 Score: {r2:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the inherited houses dataset\n",
        "inherited_houses_df = pd.read_csv('/workspace/house_project1/data/inherited_houses.csv')\n",
        "\n",
        "def clean_inherited_houses(data):\n",
        "    # Handling missing values:\n",
        "    # Fill missing numerical values with the median\n",
        "    for column in data.select_dtypes(include=['float64', 'int64']).columns:\n",
        "        data[column].fillna(data[column].median(), inplace=True)\n",
        "    \n",
        "    # Fill missing categorical values with the mode\n",
        "    for column in data.select_dtypes(include=['object']).columns:\n",
        "        data[column].fillna(data[column].mode()[0], inplace=True)\n",
        "\n",
        "    # Feature Engineering:\n",
        "    # Create new features: HouseAge and YearsSinceRemodel\n",
        "    data['HouseAge'] = 2024 - data['YearBuilt']\n",
        "    data['YearsSinceRemodel'] = 2024 - data['YearRemodAdd']\n",
        "    \n",
        "    # Drop original columns if needed\n",
        "    data.drop(['YearBuilt', 'YearRemodAdd'], axis=1, inplace=True)\n",
        "    \n",
        "    # Encode Categorical Variables:\n",
        "    # Convert ordinal categories to numerical values\n",
        "    ordinal_mapping = {\n",
        "        'KitchenQual': {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
        "        'BsmtExposure': {'No': 1, 'Mn': 2, 'Av': 3, 'Gd': 4},\n",
        "        'BsmtFinType1': {'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6},\n",
        "        'GarageFinish': {'Unf': 1, 'RFn': 2, 'Fin': 3}\n",
        "    }\n",
        "    \n",
        "    for col, mapping in ordinal_mapping.items():\n",
        "        data[col] = data[col].map(mapping)\n",
        "    \n",
        "    # Perform one-hot encoding on any remaining categorical variables\n",
        "    data = pd.get_dummies(data, drop_first=True)\n",
        "    \n",
        "    # Standardize Numerical Features\n",
        "    scaler = StandardScaler()\n",
        "    numerical_features = data.select_dtypes(include=['float64', 'int64']).columns\n",
        "    data[numerical_features] = scaler.fit_transform(data[numerical_features])\n",
        "\n",
        "    # Display summary of cleaned data\n",
        "    print(\"Data after cleaning and preparation:\")\n",
        "    print(data.describe())\n",
        "    \n",
        "    return data\n",
        "\n",
        "# Clean the inherited houses dataset\n",
        "X_inherited_cleaned = clean_inherited_houses(inherited_houses_df)\n",
        "\n",
        "# Display the first few rows of the cleaned dataset\n",
        "X_inherited_cleaned.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "# Step 1: Load and prepare the inherited houses dataset\n",
        "inherited_houses_df = pd.read_csv('/workspace/house_project1/data/inherited_houses.csv')\n",
        "\n",
        "# Select the same features used in training\n",
        "X_inherited = inherited_houses_df[selected_features]\n",
        "\n",
        "# Apply the same scaler used on the training set\n",
        "X_inherited_scaled = scaler.transform(X_inherited)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data Loading and Initial Overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1: Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: Load the datasets\n",
        "inherited_houses_df = pd.read_csv('/workspace/house_project1/data/inherited_houses.csv')\n",
        "house_prices_df = pd.read_csv('/workspace/house_project1/data/house_prices_records.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inherited Houses Data:\n",
            "   1stFlrSF  2ndFlrSF  BedroomAbvGr BsmtExposure  BsmtFinSF1 BsmtFinType1  \\\n",
            "0       896         0             2           No       468.0          Rec   \n",
            "1      1329         0             3           No       923.0          ALQ   \n",
            "2       928       701             3           No       791.0          GLQ   \n",
            "3       926       678             3           No       602.0          GLQ   \n",
            "\n",
            "   BsmtUnfSF  EnclosedPorch  GarageArea GarageFinish  ...  LotArea  \\\n",
            "0      270.0              0       730.0          Unf  ...    11622   \n",
            "1      406.0              0       312.0          Unf  ...    14267   \n",
            "2      137.0              0       482.0          Fin  ...    13830   \n",
            "3      324.0              0       470.0          Fin  ...     9978   \n",
            "\n",
            "   LotFrontage MasVnrArea  OpenPorchSF  OverallCond  OverallQual  TotalBsmtSF  \\\n",
            "0         80.0        0.0            0            6            5        882.0   \n",
            "1         81.0      108.0           36            6            6       1329.0   \n",
            "2         74.0        0.0           34            5            5        928.0   \n",
            "3         78.0       20.0           36            6            6        926.0   \n",
            "\n",
            "   WoodDeckSF  YearBuilt  YearRemodAdd  \n",
            "0         140       1961          1961  \n",
            "1         393       1958          1958  \n",
            "2         212       1997          1998  \n",
            "3         360       1998          1998  \n",
            "\n",
            "[4 rows x 23 columns]\n",
            "\n",
            "House Prices Records Data:\n",
            "   1stFlrSF  2ndFlrSF  BedroomAbvGr BsmtExposure  BsmtFinSF1 BsmtFinType1  \\\n",
            "0       856     854.0           3.0           No         706          GLQ   \n",
            "1      1262       0.0           3.0           Gd         978          ALQ   \n",
            "2       920     866.0           3.0           Mn         486          GLQ   \n",
            "3       961       NaN           NaN           No         216          ALQ   \n",
            "4      1145       NaN           4.0           Av         655          GLQ   \n",
            "\n",
            "   BsmtUnfSF  EnclosedPorch  GarageArea GarageFinish  ...  LotFrontage  \\\n",
            "0        150            0.0         548          RFn  ...         65.0   \n",
            "1        284            NaN         460          RFn  ...         80.0   \n",
            "2        434            0.0         608          RFn  ...         68.0   \n",
            "3        540            NaN         642          Unf  ...         60.0   \n",
            "4        490            0.0         836          RFn  ...         84.0   \n",
            "\n",
            "   MasVnrArea OpenPorchSF  OverallCond  OverallQual  TotalBsmtSF  WoodDeckSF  \\\n",
            "0       196.0          61            5            7          856         0.0   \n",
            "1         0.0           0            8            6         1262         NaN   \n",
            "2       162.0          42            5            7          920         NaN   \n",
            "3         0.0          35            5            7          756         NaN   \n",
            "4       350.0          84            5            8         1145         NaN   \n",
            "\n",
            "   YearBuilt  YearRemodAdd  SalePrice  \n",
            "0       2003          2003     208500  \n",
            "1       1976          1976     181500  \n",
            "2       2001          2002     223500  \n",
            "3       1915          1970     140000  \n",
            "4       2000          2000     250000  \n",
            "\n",
            "[5 rows x 24 columns]\n"
          ]
        }
      ],
      "source": [
        "# Display the first few rows of each dataset\n",
        "print(\"Inherited Houses Data:\")\n",
        "print(inherited_houses_df.head())\n",
        "print(\"\\nHouse Prices Records Data:\")\n",
        "print(house_prices_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* You may add as many sections as you want, as long as they support your project workflow.\n",
        "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* If you do not need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  # create here your folder\n",
        "  # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
